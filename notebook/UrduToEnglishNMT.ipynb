{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q4ZXCWDQinMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebe0022-7c3a-4280-f2da-97aa7ba3cf6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure GPU is used\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available.\")\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "else:\n",
        "    print(\"No GPU detected. Falling back to CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAT31MzMhjaN",
        "outputId": "2ffd89e7-3f52-4113-c153-403693ff61d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the contents of the English text file\n",
        "with open(\"/content/drive/MyDrive/UNH Data Science Courses/DSCI 6011 - DL/Final Project/data/english-corpus.txt\", 'r',encoding=\"utf8\") as file:\n",
        "    english_lines = file.readlines()\n",
        "\n",
        "# Read the contents of the Urdu text file\n",
        "with open(\"/content/drive/MyDrive/UNH Data Science Courses/DSCI 6011 - DL/Final Project/data/urdu-corpus.txt\", 'r',encoding=\"utf8\") as file:\n",
        "    urdu_lines = file.readlines()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'English': english_lines, 'Urdu': urdu_lines})\n",
        "\n",
        "# Remove newline characters from the strings\n",
        "df['English'] = df['English'].str.strip()\n",
        "df['Urdu'] = df['Urdu'].str.strip()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Lm1mLS3Va9KS",
        "outputId": "2c024220-7036-4570-a229-e36a4ccc4ee9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                English                       Urdu\n",
              "0   is zain your nephew      زین تمہارا بھتیجا ہے۔\n",
              "1  i wish youd trust me  کاش تم مجھ پر بھروسہ کرتے\n",
              "2      did he touch you      کیا اس نے آپ کو چھوا؟\n",
              "3      its part of life         اس کی زندگی کا حصہ\n",
              "4        zain isnt ugly        زین بدصورت نہیں ہے۔"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6554b416-1447-4e0c-86ac-3b9b9766876c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Urdu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is zain your nephew</td>\n",
              "      <td>زین تمہارا بھتیجا ہے۔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i wish youd trust me</td>\n",
              "      <td>کاش تم مجھ پر بھروسہ کرتے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>did he touch you</td>\n",
              "      <td>کیا اس نے آپ کو چھوا؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>its part of life</td>\n",
              "      <td>اس کی زندگی کا حصہ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zain isnt ugly</td>\n",
              "      <td>زین بدصورت نہیں ہے۔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6554b416-1447-4e0c-86ac-3b9b9766876c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6554b416-1447-4e0c-86ac-3b9b9766876c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6554b416-1447-4e0c-86ac-3b9b9766876c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96d632a9-6943-4d07-ad2f-9675f53a1263\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96d632a9-6943-4d07-ad2f-9675f53a1263')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96d632a9-6943-4d07-ad2f-9675f53a1263 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24525,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24003,\n        \"samples\": [\n          \"zain knew everything\",\n          \"where is the closest pakistani restaurant\",\n          \"here are the rules\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Urdu\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22904,\n        \"samples\": [\n          \"\\u0645\\u06cc\\u06ba \\u0641\\u0679 \\u0628\\u0627\\u0644 \\u06a9\\u06be\\u06cc\\u0644\\u0646\\u0627 \\u067e\\u0633\\u0646\\u062f \\u06a9\\u0631\\u062a\\u0627 \\u06c1\\u0648\\u06ba\",\n          \"\\u0627\\u0633 \\u0645\\u0646\\u062f\\u0631 \\u06a9\\u0648 \\u062a\\u0628\\u0627\\u06c1 \\u06a9\\u0631 \\u062f\\u0648\",\n          \"\\u0627\\u06cc\\u06a9 \\u0628\\u0644\\u06cc \\u06a9\\u06cc \\u0633\\u0627\\u062a \\u0632\\u0646\\u062f\\u06af\\u06cc\\u0627\\u06ba \\u06c1\\u06cc\\u06ba\\u06d4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the maximum length of the sentences in either language\n",
        "max_length_english = max(df['English'].str.split().apply(len))\n",
        "max_length_urdu = max(df['Urdu'].str.split().apply(len))\n",
        "max_sequence_length = max(max_length_english, max_length_urdu)\n",
        "\n",
        "# Add start and end tokens\n",
        "df['English'] = \"<start> \" + df['English'] + \" <end>\"\n",
        "df['Urdu'] = \"<start> \" + df['Urdu'] + \" <end>\"\n",
        "\n",
        "# Ensure tokenizers handle padding explicitly\n",
        "english_tokenizer = tf.keras.layers.TextVectorization(output_sequence_length=max_sequence_length, ragged=False)\n",
        "urdu_tokenizer = tf.keras.layers.TextVectorization(output_sequence_length=max_sequence_length, ragged=False)\n",
        "\n",
        "# Adapt tokenizers\n",
        "english_tokenizer.adapt([\"<pad>\", \"<start>\", \"<end>\"] + list(df['English']))\n",
        "urdu_tokenizer.adapt([\"<pad>\", \"<start>\", \"<end>\"] + list(df['Urdu']))\n",
        "\n",
        "# Tokenize data\n",
        "english_sequences = english_tokenizer(df['English']).numpy()\n",
        "urdu_sequences = urdu_tokenizer(df['Urdu']).numpy()\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    urdu_sequences, english_sequences, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SLZL1sU3cmUU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shift decoder targets\n",
        "def create_shifted_targets(y):\n",
        "    return y[:, :-1], y[:, 1:]\n",
        "\n",
        "train_decoder_input, train_decoder_target = create_shifted_targets(y_train)\n",
        "val_decoder_input, val_decoder_target = create_shifted_targets(y_val)"
      ],
      "metadata": {
        "id": "ZtAOWC1wThq4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define padding function\n",
        "def create_padding_mask(sequence):\n",
        "    return tf.cast(tf.math.equal(sequence, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :]  # Mask shape: (batch_size, 1, 1, sequence_length)"
      ],
      "metadata": {
        "id": "iOvN6kywSnTn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder padding mask for X_train\n",
        "train_encoder_padding_mask = create_padding_mask(X_train)\n",
        "val_encoder_padding_mask = create_padding_mask(X_val)\n",
        "\n",
        "# Decoder padding mask for train_decoder_input\n",
        "train_decoder_padding_mask = create_padding_mask(train_decoder_input)\n",
        "val_decoder_padding_mask = create_padding_mask(val_decoder_input)"
      ],
      "metadata": {
        "id": "-GUPEp8tSqOI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define positinoal embedding class\n",
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.token_embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.position_embedding = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "        return self.token_embedding(x) + self.position_embedding(positions)"
      ],
      "metadata": {
        "id": "cPCrExgcf0KH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define encoder\n",
        "def transformer_encoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    inputs = layers.Input(shape=(None, embed_dim))\n",
        "    mask = layers.Input(shape=(1, 1, None))\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs, attention_mask=mask)\n",
        "    attention = layers.Dropout(dropout_rate)(attention)\n",
        "    attention = layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(attention)\n",
        "    ff = layers.Dense(embed_dim)(ff)\n",
        "    ff = layers.Dropout(dropout_rate)(ff)\n",
        "    outputs = layers.LayerNormalization(epsilon=1e-6)(attention + ff)\n",
        "    return tf.keras.Model(inputs=[inputs, mask], outputs=outputs)\n",
        "\n",
        "# Define decoder\n",
        "def transformer_decoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    enc_inputs = layers.Input(shape=(None, embed_dim))\n",
        "    dec_inputs = layers.Input(shape=(None, embed_dim))\n",
        "    mask = layers.Input(shape=(1, 1, None))\n",
        "    attention1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(dec_inputs, dec_inputs, attention_mask=mask)\n",
        "    attention1 = layers.LayerNormalization(epsilon=1e-6)(dec_inputs + attention1)\n",
        "    attention2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(attention1, enc_inputs)\n",
        "    attention2 = layers.LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(attention2)\n",
        "    ff = layers.Dense(embed_dim)(ff)\n",
        "    ff = layers.Dropout(dropout_rate)(ff)\n",
        "    outputs = layers.LayerNormalization(epsilon=1e-6)(attention2 + ff)\n",
        "    return tf.keras.Model(inputs=[enc_inputs, dec_inputs, mask], outputs=outputs)"
      ],
      "metadata": {
        "id": "QeqxtZkSStFu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model by layers\n",
        "vocab_size_english = len(english_tokenizer.get_vocabulary())\n",
        "vocab_size_urdu = len(urdu_tokenizer.get_vocabulary())\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 64\n",
        "\n",
        "# Inputs\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "encoder_mask = layers.Input(shape=(1, 1, None))\n",
        "decoder_mask = layers.Input(shape=(1, 1, None))\n",
        "\n",
        "# Encoder\n",
        "encoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_urdu, embed_dim)(encoder_inputs)\n",
        "encoder = transformer_encoder(embed_dim, num_heads, ff_dim)\n",
        "encoder_outputs = encoder([encoder_embeddings, encoder_mask])\n",
        "\n",
        "# Decoder\n",
        "decoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_english, embed_dim)(decoder_inputs)\n",
        "decoder = transformer_decoder(embed_dim, num_heads, ff_dim)\n",
        "decoder_outputs = decoder([encoder_outputs, decoder_embeddings, decoder_mask])\n",
        "\n",
        "# Output\n",
        "outputs = layers.Dense(vocab_size_english, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "# Model\n",
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs, encoder_mask, decoder_mask], outputs=outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "G1S2IgoQTEOi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate optimizer and loss function criterion\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jJxeWeIwgYxw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, train_decoder_input, train_encoder_padding_mask, train_decoder_padding_mask],\n",
        "    train_decoder_target,\n",
        "    validation_data=(\n",
        "        [X_val, val_decoder_input, val_encoder_padding_mask, val_decoder_padding_mask],\n",
        "        val_decoder_target\n",
        "    ),\n",
        "    batch_size=128,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEH-lwc-gAVd",
        "outputId": "aa0f61b0-4dd3-424b-948c-08da84333888"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 118ms/step - accuracy: 0.7246 - loss: 3.4123 - val_accuracy: 0.8110 - val_loss: 1.2078\n",
            "Epoch 2/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.8136 - loss: 1.1491 - val_accuracy: 0.8409 - val_loss: 0.9784\n",
            "Epoch 3/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8551 - loss: 0.8552 - val_accuracy: 0.8802 - val_loss: 0.7261\n",
            "Epoch 4/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8957 - loss: 0.5902 - val_accuracy: 0.9023 - val_loss: 0.5820\n",
            "Epoch 5/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9239 - loss: 0.4171 - val_accuracy: 0.9147 - val_loss: 0.5043\n",
            "Epoch 6/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9424 - loss: 0.3001 - val_accuracy: 0.9214 - val_loss: 0.4635\n",
            "Epoch 7/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9549 - loss: 0.2206 - val_accuracy: 0.9246 - val_loss: 0.4412\n",
            "Epoch 8/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9640 - loss: 0.1672 - val_accuracy: 0.9261 - val_loss: 0.4361\n",
            "Epoch 9/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9712 - loss: 0.1294 - val_accuracy: 0.9284 - val_loss: 0.4297\n",
            "Epoch 10/10\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9771 - loss: 0.0985 - val_accuracy: 0.9271 - val_loss: 0.4373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_urdu_to_english(urdu_sentence, model, urdu_tokenizer, english_tokenizer, max_sequence_length):\n",
        "    # Tokenize the Urdu sentence\n",
        "    tokenized_input = urdu_tokenizer([urdu_sentence]).numpy()\n",
        "    tokenized_input = tf.convert_to_tensor(tokenized_input)\n",
        "\n",
        "    # Create padding mask for the encoder\n",
        "    encoder_mask = create_padding_mask(tokenized_input)\n",
        "\n",
        "    # Initialize decoder input with <start> token\n",
        "    start_token = english_tokenizer(\"<start>\").numpy()[0]\n",
        "    end_token = english_tokenizer(\"<end>\").numpy()[0]\n",
        "    target_sequence = tf.convert_to_tensor([[start_token]])\n",
        "\n",
        "    # Store predicted tokens\n",
        "    predicted_tokens = []\n",
        "\n",
        "    for _ in range(max_sequence_length):\n",
        "        # Create decoder mask for the current target sequence\n",
        "        decoder_mask = create_padding_mask(target_sequence)\n",
        "\n",
        "        # Call the model with the current inputs\n",
        "        output = model([tokenized_input, target_sequence, encoder_mask, decoder_mask], training=False)\n",
        "\n",
        "        # Get the predicted token\n",
        "        predictions = output[:, -1, :]  # Get the logits for the last timestep\n",
        "        predicted_token = tf.argmax(predictions, axis=-1).numpy()[0]\n",
        "\n",
        "        # Append the predicted token\n",
        "        predicted_tokens.append(predicted_token)\n",
        "\n",
        "        # Break if <end> token is reached\n",
        "        if predicted_token == end_token:\n",
        "            break\n",
        "\n",
        "        # Update the target sequence by appending the predicted token\n",
        "        target_sequence = tf.concat([target_sequence, [[predicted_token]]], axis=-1)\n",
        "\n",
        "    # Convert tokens back to text\n",
        "    vocab = english_tokenizer.get_vocabulary()\n",
        "    translated_sentence = \" \".join([vocab[token] for token in predicted_tokens if token not in {0, start_token, end_token}])\n",
        "\n",
        "    # Print the translation\n",
        "    print(f\"Input (Urdu): {urdu_sentence}\")\n",
        "    print(f\"Translated (English): {translated_sentence}\")\n",
        "    return translated_sentence"
      ],
      "metadata": {
        "id": "PUO-3F-zeJ-z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing of unseen example urdu sentences\n",
        "urdu_sentences = [\n",
        "    \"میں اسکول جا رہا ہوں۔\",\n",
        "    \"آج موسم بہت اچھا ہے۔\",\n",
        "    \"یہ ایک خوبصورت کتاب ہے۔\",\n",
        "    \"کیا آپ مدد کر سکتے ہیں؟\",\n",
        "    \"وہ بہت اچھا کھلاڑی ہے۔\"\n",
        "]\n",
        "\n",
        "for sentence in urdu_sentences:\n",
        "    translate_urdu_to_english(sentence, model, urdu_tokenizer, english_tokenizer, max_sequence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkFzH39QpO_t",
        "outputId": "f960ca15-4283-45f2-f1cb-4bd943a59ec2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (Urdu): میں اسکول جا رہا ہوں۔\n",
            "Translated (English): to be going to school\n",
            "Input (Urdu): آج موسم بہت اچھا ہے۔\n",
            "Translated (English): the weather is so well today\n",
            "Input (Urdu): یہ ایک خوبصورت کتاب ہے۔\n",
            "Translated (English): a is a beautiful book\n",
            "Input (Urdu): کیا آپ مدد کر سکتے ہیں؟\n",
            "Translated (English): can you do help me\n",
            "Input (Urdu): وہ بہت اچھا کھلاڑی ہے۔\n",
            "Translated (English): a great of great player\n"
          ]
        }
      ]
    }
  ]
}