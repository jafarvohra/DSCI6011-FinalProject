{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q4ZXCWDQinMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d1eba8-f01f-4deb-b35f-3db467754bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries and functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure GPU is used\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available.\")\n",
        "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
        "else:\n",
        "    print(\"No GPU detected. Falling back to CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAT31MzMhjaN",
        "outputId": "2fd9e59f-e0f0-41f5-fd89-da6c72bb52c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the contents of the English text file\n",
        "with open(\"/content/drive/MyDrive/UNH Data Science Courses/DSCI 6011 - DL/Final Project/data/english-corpus.txt\", 'r',encoding=\"utf8\") as file:\n",
        "    english_lines = file.readlines()\n",
        "\n",
        "# Read the contents of the Urdu text file\n",
        "with open(\"/content/drive/MyDrive/UNH Data Science Courses/DSCI 6011 - DL/Final Project/data/urdu-corpus.txt\", 'r',encoding=\"utf8\") as file:\n",
        "    urdu_lines = file.readlines()\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'English': english_lines, 'Urdu': urdu_lines})\n",
        "\n",
        "# Remove newline characters from the strings\n",
        "df['English'] = df['English'].str.strip()\n",
        "df['Urdu'] = df['Urdu'].str.strip()\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Lm1mLS3Va9KS",
        "outputId": "1dd60e31-f73b-404a-c06d-02365b9c4b43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                English                       Urdu\n",
              "0   is zain your nephew      زین تمہارا بھتیجا ہے۔\n",
              "1  i wish youd trust me  کاش تم مجھ پر بھروسہ کرتے\n",
              "2      did he touch you      کیا اس نے آپ کو چھوا؟\n",
              "3      its part of life         اس کی زندگی کا حصہ\n",
              "4        zain isnt ugly        زین بدصورت نہیں ہے۔"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43e386c6-2c67-4454-938a-efb758295e99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Urdu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is zain your nephew</td>\n",
              "      <td>زین تمہارا بھتیجا ہے۔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i wish youd trust me</td>\n",
              "      <td>کاش تم مجھ پر بھروسہ کرتے</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>did he touch you</td>\n",
              "      <td>کیا اس نے آپ کو چھوا؟</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>its part of life</td>\n",
              "      <td>اس کی زندگی کا حصہ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>zain isnt ugly</td>\n",
              "      <td>زین بدصورت نہیں ہے۔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43e386c6-2c67-4454-938a-efb758295e99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43e386c6-2c67-4454-938a-efb758295e99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43e386c6-2c67-4454-938a-efb758295e99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b4ec2b6-1b2b-44fd-a390-9eb1640be704\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b4ec2b6-1b2b-44fd-a390-9eb1640be704')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b4ec2b6-1b2b-44fd-a390-9eb1640be704 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 24525,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24003,\n        \"samples\": [\n          \"zain knew everything\",\n          \"where is the closest pakistani restaurant\",\n          \"here are the rules\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Urdu\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22904,\n        \"samples\": [\n          \"\\u0645\\u06cc\\u06ba \\u0641\\u0679 \\u0628\\u0627\\u0644 \\u06a9\\u06be\\u06cc\\u0644\\u0646\\u0627 \\u067e\\u0633\\u0646\\u062f \\u06a9\\u0631\\u062a\\u0627 \\u06c1\\u0648\\u06ba\",\n          \"\\u0627\\u0633 \\u0645\\u0646\\u062f\\u0631 \\u06a9\\u0648 \\u062a\\u0628\\u0627\\u06c1 \\u06a9\\u0631 \\u062f\\u0648\",\n          \"\\u0627\\u06cc\\u06a9 \\u0628\\u0644\\u06cc \\u06a9\\u06cc \\u0633\\u0627\\u062a \\u0632\\u0646\\u062f\\u06af\\u06cc\\u0627\\u06ba \\u06c1\\u06cc\\u06ba\\u06d4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the maximum length of the sentences in either language\n",
        "max_length_english = max(df['English'].str.split().apply(len))\n",
        "max_length_urdu = max(df['Urdu'].str.split().apply(len))\n",
        "max_sequence_length = max(max_length_english, max_length_urdu)\n",
        "\n",
        "# Tokenizer\n",
        "english_tokenizer = tf.keras.layers.TextVectorization(output_sequence_length=max_sequence_length)\n",
        "urdu_tokenizer = tf.keras.layers.TextVectorization(output_sequence_length=max_sequence_length)\n",
        "\n",
        "# Adapt tokenizers\n",
        "english_tokenizer.adapt(df['English'])\n",
        "urdu_tokenizer.adapt(df['Urdu'])\n",
        "\n",
        "# Tokenize data\n",
        "english_sequences = english_tokenizer(df['English']).numpy()\n",
        "urdu_sequences = urdu_tokenizer(df['Urdu']).numpy()\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    urdu_sequences, english_sequences, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SLZL1sU3cmUU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.token_embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.position_embedding = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "        return self.token_embedding(x) + self.position_embedding(positions)\n",
        "\n",
        "def transformer_encoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    inputs = layers.Input(shape=(None, embed_dim))\n",
        "    attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
        "    attention = layers.Dropout(dropout_rate)(attention)\n",
        "    attention = layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(attention)\n",
        "    ff = layers.Dense(embed_dim)(ff)\n",
        "    ff = layers.Dropout(dropout_rate)(ff)\n",
        "    outputs = layers.LayerNormalization(epsilon=1e-6)(attention + ff)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "def transformer_decoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "    enc_inputs = layers.Input(shape=(None, embed_dim))\n",
        "    dec_inputs = layers.Input(shape=(None, embed_dim))\n",
        "    attention1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(dec_inputs, dec_inputs)\n",
        "    attention1 = layers.LayerNormalization(epsilon=1e-6)(dec_inputs + attention1)\n",
        "    attention2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(attention1, enc_inputs)\n",
        "    attention2 = layers.LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
        "    ff = layers.Dense(ff_dim, activation=\"relu\")(attention2)\n",
        "    ff = layers.Dense(embed_dim)(ff)\n",
        "    ff = layers.Dropout(dropout_rate)(ff)\n",
        "    outputs = layers.LayerNormalization(epsilon=1e-6)(attention2 + ff)\n",
        "    return tf.keras.Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)"
      ],
      "metadata": {
        "id": "cPCrExgcf0KH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class PositionalEncoding(layers.Layer):\n",
        "#     def __init__(self, sequence_length, vocab_size, embed_dim):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         self.token_embedding = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "#         self.position_embedding = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
        "\n",
        "#     def call(self, x):\n",
        "#         positions = tf.range(start=0, limit=tf.shape(x)[1], delta=1)\n",
        "#         return self.token_embedding(x) + self.position_embedding(positions)\n",
        "\n",
        "# class PaddingMask(layers.Layer):\n",
        "#     def call(self, inputs):\n",
        "#         mask = tf.cast(tf.math.not_equal(inputs, 0), tf.float32)\n",
        "#         return mask[:, tf.newaxis, tf.newaxis, :]  # Add extra dimensions to match the attention mask shape\n",
        "\n",
        "# def transformer_encoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "#     inputs = layers.Input(shape=(None, embed_dim))\n",
        "#     mask = layers.Input(shape=(1, 1, None), dtype=tf.float32)  # Mask input\n",
        "\n",
        "#     attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs, attention_mask=mask)\n",
        "#     attention = layers.Dropout(dropout_rate)(attention)\n",
        "#     attention = layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "#     ff = layers.Dense(ff_dim, activation=\"relu\")(attention)\n",
        "#     ff = layers.Dense(embed_dim)(ff)\n",
        "#     ff = layers.Dropout(dropout_rate)(ff)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention + ff)\n",
        "#     return tf.keras.Model(inputs=[inputs, mask], outputs=outputs)\n",
        "\n",
        "# def transformer_decoder(embed_dim, num_heads, ff_dim, dropout_rate=0.1):\n",
        "#     enc_inputs = layers.Input(shape=(None, embed_dim))\n",
        "#     dec_inputs = layers.Input(shape=(None, embed_dim))\n",
        "#     enc_mask = layers.Input(shape=(1, 1, None), dtype=tf.float32)  # Encoder mask input\n",
        "#     dec_mask = layers.Input(shape=(1, 1, None), dtype=tf.float32)  # Decoder mask input\n",
        "\n",
        "#     attention1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(dec_inputs, dec_inputs, attention_mask=dec_mask)\n",
        "#     attention1 = layers.LayerNormalization(epsilon=1e-6)(dec_inputs + attention1)\n",
        "#     attention2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(attention1, enc_inputs, attention_mask=enc_mask)\n",
        "#     attention2 = layers.LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
        "#     ff = layers.Dense(ff_dim, activation=\"relu\")(attention2)\n",
        "#     ff = layers.Dense(embed_dim)(ff)\n",
        "#     ff = layers.Dropout(dropout_rate)(ff)\n",
        "#     outputs = layers.LayerNormalization(epsilon=1e-6)(attention2 + ff)\n",
        "#     return tf.keras.Model(inputs=[enc_inputs, dec_inputs, enc_mask, dec_mask], outputs=outputs)"
      ],
      "metadata": {
        "id": "aaWXkRD_9Kw3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Example usage\n",
        "# vocab_size_english = len(english_tokenizer.get_vocabulary())\n",
        "# vocab_size_urdu = len(urdu_tokenizer.get_vocabulary())\n",
        "# max_vocab_length = max(vocab_size_english, vocab_size_urdu)\n",
        "# embed_dim = max_vocab_length\n",
        "# num_heads = 4\n",
        "# ff_dim = 64\n",
        "# max_sequence_length = 50\n",
        "\n",
        "# encoder_inputs = layers.Input(shape=(None,))\n",
        "# decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# encoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_urdu, embed_dim)(encoder_inputs)\n",
        "# decoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_english, embed_dim)(decoder_inputs)\n",
        "\n",
        "# # Create masks using the custom PaddingMask layer\n",
        "# enc_mask = PaddingMask()(encoder_inputs)\n",
        "# dec_mask = PaddingMask()(decoder_inputs)\n",
        "\n",
        "# encoder = transformer_encoder(embed_dim, num_heads, ff_dim)\n",
        "# encoder_outputs = encoder([encoder_embeddings, enc_mask])\n",
        "\n",
        "# decoder = transformer_decoder(embed_dim, num_heads, ff_dim)\n",
        "# decoder_outputs = decoder([encoder_outputs, decoder_embeddings, enc_mask, dec_mask])\n",
        "\n",
        "# outputs = layers.Dense(vocab_size_english, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "# model = tf.keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
        "# model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "oQFoP_XW_ARY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Build and Compile the Model\n",
        "vocab_size_english = len(english_tokenizer.get_vocabulary())\n",
        "vocab_size_urdu = len(urdu_tokenizer.get_vocabulary())\n",
        "embed_dim = 32\n",
        "num_heads = 4\n",
        "ff_dim = 64\n",
        "\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "encoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_urdu, embed_dim)(encoder_inputs)\n",
        "decoder_embeddings = PositionalEncoding(max_sequence_length, vocab_size_english, embed_dim)(decoder_inputs)\n",
        "\n",
        "encoder = transformer_encoder(embed_dim, num_heads, ff_dim)\n",
        "encoder_outputs = encoder(encoder_embeddings)\n",
        "\n",
        "decoder = transformer_decoder(embed_dim, num_heads, ff_dim)\n",
        "decoder_outputs = decoder([encoder_outputs, decoder_embeddings])\n",
        "\n",
        "outputs = layers.Dense(vocab_size_english, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "SoCeKv2Qf8so"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the Model\n",
        "def create_shifted_targets(y):\n",
        "    return y[:, :-1], y[:, 1:]\n",
        "\n",
        "train_decoder_input, train_decoder_target = create_shifted_targets(y_train)\n",
        "val_decoder_input, val_decoder_target = create_shifted_targets(y_val)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, train_decoder_input], train_decoder_target,\n",
        "    validation_data=([X_val, val_decoder_input], val_decoder_target),\n",
        "    batch_size=128,\n",
        "    epochs=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEH-lwc-gAVd",
        "outputId": "306c1b09-fd2a-4de7-853c-15c90394a4bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - accuracy: 0.7728 - loss: 6.1312 - val_accuracy: 0.8320 - val_loss: 1.2471\n",
            "Epoch 2/3\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8399 - loss: 1.1588 - val_accuracy: 0.8522 - val_loss: 0.9968\n",
            "Epoch 3/3\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8559 - loss: 0.9478 - val_accuracy: 0.8682 - val_loss: 0.8678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_urdu_to_english(urdu_sentence, model, urdu_tokenizer, english_tokenizer, max_sequence_length):\n",
        "    \"\"\"\n",
        "    Translates a given Urdu sentence to English using the trained model.\n",
        "\n",
        "    Args:\n",
        "        urdu_sentence (str): The Urdu input sentence to be translated.\n",
        "        model (tf.keras.Model): The trained Transformer model.\n",
        "        urdu_tokenizer (tf.keras.layers.TextVectorization): Tokenizer for Urdu text.\n",
        "        english_tokenizer (tf.keras.layers.TextVectorization): Tokenizer for English text.\n",
        "        max_sequence_length (int): Maximum sequence length for translation.\n",
        "\n",
        "    Returns:\n",
        "        str: The translated English sentence.\n",
        "    \"\"\"\n",
        "    # Tokenize the Urdu input sentence\n",
        "    tokenized_input = urdu_tokenizer([urdu_sentence]).numpy()\n",
        "    tokenized_input = tf.convert_to_tensor(tokenized_input)\n",
        "\n",
        "    # Start with the <start> token in the target sequence\n",
        "    start_token = english_tokenizer(\"<start>\").numpy()[0]\n",
        "    end_token = english_tokenizer(\"<end>\").numpy()[0]\n",
        "    target_sequence = tf.convert_to_tensor([[start_token]])  # Shape: (1, 1)\n",
        "\n",
        "    # Placeholder for storing the predicted tokens\n",
        "    predicted_tokens = []\n",
        "\n",
        "    for _ in range(max_sequence_length):\n",
        "        # Pass inputs through the model\n",
        "        output = model([tokenized_input, target_sequence], training=False)\n",
        "\n",
        "        # Extract the logits of the last time step\n",
        "        predictions = output[:, -1, :]  # Shape: (1, vocab_size)\n",
        "\n",
        "        # Get the predicted token (argmax)\n",
        "        predicted_token = tf.argmax(predictions, axis=-1).numpy()[0]\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        predicted_tokens.append(predicted_token)\n",
        "\n",
        "        # Check if the <end> token is reached\n",
        "        if predicted_token == end_token:\n",
        "            break\n",
        "\n",
        "        # Append the predicted token to the target sequence for the next step\n",
        "        target_sequence = tf.concat([target_sequence, [[predicted_token]]], axis=-1)\n",
        "\n",
        "    # Convert predicted tokens back to words using the vocabulary\n",
        "    vocab = english_tokenizer.get_vocabulary()\n",
        "    translated_sentence = \" \".join([vocab[token] for token in predicted_tokens if token > 0])\n",
        "\n",
        "    # Print the input and translated sentence\n",
        "    print(f\"Input (Urdu): {urdu_sentence}\")\n",
        "    print(f\"Translated (English): {translated_sentence}\")\n",
        "\n",
        "    return translated_sentence"
      ],
      "metadata": {
        "id": "NzRGQ3tapFIV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "urdu_sentences = [\n",
        "    \"میں اسکول جا رہا ہوں۔\",\n",
        "    \"آج موسم بہت اچھا ہے۔\",\n",
        "    \"یہ ایک خوبصورت کتاب ہے۔\",\n",
        "    \"کیا آپ مدد کر سکتے ہیں؟\",\n",
        "    \"وہ بہت اچھا کھلاڑی ہے۔\"\n",
        "]\n",
        "\n",
        "for sentence in urdu_sentences:\n",
        "    translate_urdu_to_english(\n",
        "        urdu_sentence=sentence,\n",
        "        model=model,\n",
        "        urdu_tokenizer=urdu_tokenizer,\n",
        "        english_tokenizer=english_tokenizer,\n",
        "        max_sequence_length=max_sequence_length\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkFzH39QpO_t",
        "outputId": "4ad84960-8167-4f7d-a965-4cc3af4a9f7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (Urdu): میں اسکول جا رہا ہوں۔\n",
            "Translated (English): a a a a a a a a a a a a a a a a a a a\n",
            "Input (Urdu): آج موسم بہت اچھا ہے۔\n",
            "Translated (English): is a a a a a a a a a a a a a a a a a a\n",
            "Input (Urdu): یہ ایک خوبصورت کتاب ہے۔\n",
            "Translated (English): is a a a a a a a a a a a a a a a a a a\n",
            "Input (Urdu): کیا آپ مدد کر سکتے ہیں؟\n",
            "Translated (English): you have you you you have you you am you you have you have you have you have you\n",
            "Input (Urdu): وہ بہت اچھا کھلاڑی ہے۔\n",
            "Translated (English): is a a a a a a a a a a a a a a a a a a\n"
          ]
        }
      ]
    }
  ]
}